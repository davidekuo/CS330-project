{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = json.load(open('data/dataset.json'))\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with 50%\n",
    "# values of original dataframe\n",
    "train_df = df.sample(frac = 0.8)\n",
    " \n",
    "# Creating dataframe with\n",
    "# rest of the 50% values\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[:100].to_json('data/train.json')\n",
    "test_df[:10].to_json('data/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precompute SMILES embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_smiles = set()\n",
    "\n",
    "for l in df.smiles_0:\n",
    "    l = map(lambda x: x[0], l)\n",
    "    all_smiles.update(l)\n",
    "\n",
    "for l in df.smiles_1:\n",
    "    l = map(lambda x: x[0], l)\n",
    "    all_smiles.update(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "smiles_model = AutoModelForMaskedLM.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_inputs = [\n",
    "    'Cn1c(=O)n(Cc2ccccc2)c(=O)c2cc(COCc3ccccc3)cnc21',\n",
    "    'CC(CC(=O)CC(C)C1CC(=O)C2(C)C3=C(C(=O)CC12C)C1(C)CCC(O)C(C)(C)C1CC3O)C(=O)O',\n",
    "    # 'O=C(NC1CCCN(Cc2cccc3ccccc23)C1)N1CCC2NNC(c3ccc4nccn4c3)C2C1',\n",
    "    # \"Cc1cc(Nc2cc(N3CCN(C)CC3)nc(Sc3ccc(NC(=O)C4CC4)cc3)n2)n[nH]1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tokenized_inputs = smiles_tokenizer(smiles_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "smiles_raw_outputs = smiles_model(**smiles_tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_mask = torch.unsqueeze(smiles_tokenized_inputs['attention_mask'], dim=2)\n",
    "smiles_logits = smiles_raw_outputs.logits\n",
    "smiles_logits = smiles_logits.masked_fill(smiles_mask == 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tokenized_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens = torch.sum(smiles_tokenized_inputs['attention_mask'], dim=1)\n",
    "seq_lens = seq_lens.reshape((-1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smiles_logits.shape, seq_lens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_logits_avg = torch.sum(smiles_logits / seq_lens, dim=1)\n",
    "smiles_logits_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_smiles_embeddings = torch.sum(smiles_logits, dim=1) \n",
    "pooled_smiles_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smiles_embeddings(smiles_inputs, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Returns a tensor of pretrained SMILES embeddings for the given SMILES inputs.\n",
    "    \"\"\"    \n",
    "    smiles_tokenized_inputs = tokenizer(smiles_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    smiles_raw_outputs = model(**smiles_tokenized_inputs)\n",
    "\n",
    "    smiles_mask = torch.unsqueeze(smiles_tokenized_inputs['attention_mask'], dim=2)\n",
    "    smiles_logits = smiles_raw_outputs.logits\n",
    "    smiles_logits = smiles_logits.masked_fill(smiles_mask == 0, 0)\n",
    "\n",
    "    # pooled_smiles_embeddings = torch.sum(smiles_logits, dim=1) \n",
    "    seq_lens = torch.sum(smiles_tokenized_inputs['attention_mask'], dim=1)\n",
    "    seq_lens = seq_lens.reshape((-1,1,1))\n",
    "    smiles_logits_avg = torch.sum(smiles_logits / seq_lens, dim=1)\n",
    "\n",
    "    return smiles_logits_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_to_embeddings = {}\n",
    "for smiles in tqdm(all_smiles):\n",
    "    embed = get_smiles_embeddings([smiles], smiles_tokenizer, smiles_model)\n",
    "    smiles_to_embeddings[smiles] = embed[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/smiles_to_embeddings_v2.pickle', 'wb') as f:\n",
    "    pickle.dump(smiles_to_embeddings, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/smiles_to_embeddings_v2.pickle', 'rb') as f:\n",
    "    loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_batch_0 = [\n",
    "    'O=C(NC1CCCN(Cc2cccc3ccccc23)C1)N1CCC2NNC(c3ccc4nccn4c3)C2C1',\n",
    "    \"Cc1cc(Nc2cc(N3CCN(C)CC3)nc(Sc3ccc(NC(=O)C4CC4)cc3)n2)n[nH]1\",\n",
    "]\n",
    "\n",
    "smiles_batch_1 = [\n",
    "    'Cn1c(=O)n(Cc2ccccc2)c(=O)c2cc(COCc3ccccc3)cnc21',\n",
    "    'CC(CC(=O)CC(C)C1CC(=O)C2(C)C3=C(C(=O)CC12C)C1(C)CCC(O)C(C)(C)C1CC3O)C(=O)O',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(list(map(lambda s: loaded[s], smiles_batch_0))).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('cs330project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14c5e36cfe7692e69c30df5a390660492f94017a814892001f2df2621be2f1d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
