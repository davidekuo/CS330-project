{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data_loader import DataGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lstm import BlackBoxLSTM\n",
    "from bert import SmilesBertModel\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "meta_batch_size = 128\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlackBoxLSTM(\n",
       "  (layer1): LSTM(769, 128, batch_first=True)\n",
       "  (dropout): Dropout(p=0.35, inplace=False)\n",
       "  (layer2): LSTM(768, 2, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iterable = DataGenerator(\n",
    "    data_json_path=f'data/test.json',\n",
    "    k=k,\n",
    "    repr=\"concat_after\",\n",
    ")\n",
    "test_loader = iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        test_iterable,\n",
    "        batch_size=meta_batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "model = torch.load(\"model/lstm_full_concat_after.pt\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM\n",
    "num_correct = 0\n",
    "N = 1000\n",
    "for _ in tqdm(range(N)):\n",
    "    i, l = next(test_loader)\n",
    "    i, l = i.to(device), l.to(device)\n",
    "    pred = model(i, l).detach()\n",
    "    # pred ~ (B, K+1, N, N)\n",
    "    # model sees K support examples for each of N classes and predicts on 1 query example for each of N classes (all shuffled ofc) -> (_, K+1, N, _)\n",
    "    # here, LSTM outputs logits for each of N classes for each of the (K+1) * N support & query examples -> (_, K+1, N, N)\n",
    "    # batch to leverage parallelism -> (B, K+1, N, N)\n",
    "\n",
    "    pred = torch.reshape(\n",
    "        pred,\n",
    "        [\n",
    "            -1,\n",
    "            k + 1,\n",
    "            num_classes,\n",
    "            num_classes,\n",
    "        ],\n",
    "    )  # no change, already in correct shape\n",
    "    pred_class = torch.argmax(pred[:, -1, :, :], axis=2)\n",
    "    # pred[:, -1, :, :] selects logits for query example (not K support examples) over entire batch, shape ~ (B, N, N)\n",
    "    # torch.argmax(..., axis=2) selects predicted class (with largest logit) for the N query examples (1 for each class), shape ~ (B, N)\n",
    "    true_class = torch.argmax(l[:, -1, :, :], axis=2)  # selects ground-truth class for the N query examples\n",
    "    num_correct += pred_class.eq(true_class).sum().item()  # sums the number of matches between predicted and ground-truth class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy\", num_correct / (meta_batch_size * num_classes * N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT\n",
    "num_correct = 0\n",
    "N = 1000\n",
    "for _ in tqdm(range(N)):\n",
    "    i, l = next(test_loader)\n",
    "    i, l = i.to(device), l.to(device)\n",
    "    attention_mask = torch.ones((meta_batch_size, (k+1)*num_classes))\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    _, pred = model(i.float(), l.float(), attention_mask)\n",
    "    # pred ~ (B, K+1, N, N)\n",
    "    # model sees K support examples for each of N classes and predicts on 1 query example for each of N classes (all shuffled ofc) -> (_, K+1, N, _)\n",
    "    # here, LSTM outputs logits for each of N classes for each of the (K+1) * N support & query examples -> (_, K+1, N, N)\n",
    "    # batch to leverage parallelism -> (B, K+1, N, N)\n",
    "\n",
    "    pred_class = torch.argmax(pred, axis=1)\n",
    "    # pred[:, -1, :, :] selects logits for query example (not K support examples) over entire batch, shape ~ (B, N, N)\n",
    "    # torch.argmax(..., axis=2) selects predicted class (with largest logit) for the N query examples (1 for each class), shape ~ (B, N)\n",
    "    true_class = torch.argmax(l[:, -1, :, :], axis=2)  # selects ground-truth class for the N query examples\n",
    "    num_correct += pred_class.eq(true_class).sum().item()  # sums the number of matches between predicted and ground-truth class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy\", num_correct / (meta_batch_size * num_classes * N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cs330')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0ff75cf23da80adcc9f356df2f104d0dd849597226f7b6e4b651ec67f115766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
